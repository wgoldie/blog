{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic differentiation blog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make some toy languages. They are going to be \"lsps\" - or not quite lisps. They are missing some key features that most lisps have. They aren't even all Turing complete. Lisp syntax is used, because it's easy to parse, and parsing is not the interest here.\n",
    "\n",
    "Each language is defined by a value type, an operator type, an atomizer, and an environment.\n",
    "\n",
    "The environment is a set of predefined operator and values.\n",
    "\n",
    "The atomizer converts atomic strings parsed from the syntax into atomic values.\n",
    "\n",
    "Code for a given lsp is parsed into nested, operator-headed lists. Each element of these lists is a list, an operator, or a value (of the correct type for this lsp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from functools import reduce\n",
    "import re\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lsp(object):\n",
    "    open_paren = re.compile(\"\\(\")\n",
    "    close_paren = re.compile(\"\\)\")\n",
    "    splitter = re.compile(\"\\s+\")\n",
    "\n",
    "    def __init__(self, value_type, operator_type, atomizer, environment):\n",
    "        self.value_type = value_type\n",
    "        self.operator_type = operator_type\n",
    "        self.atomizer = atomizer\n",
    "        self.environment = environment\n",
    "        \n",
    "    def parse_helper(self, tokens):\n",
    "        token = tokens.pop(0)\n",
    "        if token == \"(\":\n",
    "            els = []\n",
    "            while tokens[0] != \")\":\n",
    "                next_expr, tokens = self.parse_helper(tokens)\n",
    "                els += [next_expr]\n",
    "\n",
    "            return els, tokens[1:]\n",
    "        elif token == \")\":\n",
    "            raise ValueError()\n",
    "        else:\n",
    "            return self.atomize(token), tokens\n",
    "        \n",
    "    def parse(self, tokens):\n",
    "        parsed, _ = self.parse_helper(tokens)\n",
    "        return parsed\n",
    "    \n",
    "    def atomize(self, token):\n",
    "        if token in self.environment.keys():\n",
    "            return self.environment[token]\n",
    "        return self.atomizer(token)\n",
    "    \n",
    "    def tokenize(self, code_str):\n",
    "        return list(filter(\n",
    "            lambda x: x is not '', \n",
    "            Lsp.splitter.split(Lsp.close_paren.sub(\" ) \", Lsp.open_paren.sub(\" ( \", code_str)))\n",
    "        ))\n",
    "        \n",
    "    def eval_stack(self, stack):\n",
    "        if isinstance(stack, self.value_type) or isinstance(stack, self.operator_type):\n",
    "            # atom\n",
    "            return stack\n",
    "\n",
    "        fn = stack[0]\n",
    "\n",
    "        if isinstance(fn, list):\n",
    "            # nested function\n",
    "            return self.eval_stack(self.eval_stack(stack[0]) + stack[1:])\n",
    "\n",
    "        if isinstance(fn, self.operator_type):\n",
    "            # eval this function on the args\n",
    "            return fn(*map(self.eval_stack, stack[1:]))\n",
    "    \n",
    "        raise ValueError(f\"Unparsable value {fn}\")\n",
    "        \n",
    "    def eval_str(self, code_str):\n",
    "        raise NotImplemented()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lsplsp\n",
    "\n",
    "Lsplsp is about the simplest we can get. It can run a few functions on Python ints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLsp(Lsp):\n",
    "    \"\"\"A DoubleLsp is an Lsp that returns the same value in the forward and backward results.\"\"\"\n",
    "    def eval_str(self, code_str):\n",
    "        stack = self.parse(self.tokenize(code_str))\n",
    "        evaled = self.eval_stack(stack)\n",
    "        return (evaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [],
   "source": [
    "LspLspValue = int\n",
    "class LspLspOperator(object):\n",
    "    \"\"\"An lsplsp operator is just a Python function annotated with a symbol.\"\"\"\n",
    "    def __init__(self, symbol, function):\n",
    "        self.symbol = symbol\n",
    "        self.function = function\n",
    "    def __call__(self, *args):\n",
    "        return self.function(*args)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_token = re.compile(\"^\\d+$\")\n",
    "\n",
    "\n",
    "def lsplsp_atomizer(atom):\n",
    "    \"\"\"Lsplsp attempts to evaluate anything it can't find in it's environment as a Python int.\"\"\"\n",
    "    if int_token.match(atom):\n",
    "        return int(atom)\n",
    "    raise ValueError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsplsp_sum = LspLspOperator('+', lambda *args: sum(args))\n",
    "lsplsp_diff = LspLspOperator('-', lambda *args: args[0] - sum(args[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsplsp = SimpleLsp(\n",
    "    LspLspValue,\n",
    "    LspLspOperator,\n",
    "    lsplsp_atomizer,\n",
    "    { f.symbol: f for f in [lsplsp_sum, lsplsp_diff] }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 633,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsplsp.eval_str(\"(+ 5 2 (- 6 3))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward-backward lsps\n",
    "\n",
    "The rest of the lsps we're going to take a look at are \"forward-backward lsps,\" or fb-lsps for short.\n",
    "\n",
    "There are two interesting characteristics of fb-lsps: \n",
    "\n",
    "1. Evaluation of an fb-lsp expression returns all the intermediate results in a nested structure.\n",
    "1. Evaluation of an fb-lsp expression results in two results: a 'forward' results and a 'backward' result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can reimplement lsplsp as fblsplsp, an fb-lsp that returns the same value in F and B results. \n",
    "It's cheating a little to call this an fb-lsp, but we'll do it anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FBCheatLsp(Lsp):\n",
    "    \"\"\"An Lsp that that returns the same value in the forward and backward results.\"\"\"\n",
    "    def eval_str(self, code_str):\n",
    "        stack = self.parse(self.tokenize(code_str))\n",
    "        evaled = self.eval_stack(stack)\n",
    "        return (\n",
    "            evaled,\n",
    "            evaled\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "FBLspLspValue = int\n",
    "class FBLspLspOperator(object):\n",
    "    \"\"\"An fblsplsp function returns the argument values in a tuple with the result.\"\"\"\n",
    "    def __init__(self, symbol, function):\n",
    "        self.symbol = symbol\n",
    "        self.function = function\n",
    "    def __call__(self, *args):\n",
    "        return (self.function(*(arg if isinstance(arg, FBLspLspValue) else arg[0] for arg in args)), args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [],
   "source": [
    "fblsplsp_sum = FBLspLspOperator('+', lambda *args: sum(args))\n",
    "fblsplsp_diff = FBLspLspOperator('-', lambda *args: args[0] - sum(args[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "fblsplsp = FBCheatLsp(\n",
    "    FBLspLspValue,\n",
    "    FBLspLspOperator,\n",
    "    lsplsp_atomizer,\n",
    "    { f.symbol: f for f in [fblsplsp_sum, fblsplsp_diff] }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, (5, 2, (3, (6, 3)))), (10, (5, 2, (3, (6, 3)))))"
      ]
     },
     "execution_count": 639,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fblsplsp.eval_str(\"(+ 5 2 (- 6 3))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This isn't very useful or interesting, though it is potentially nice to have those intermediate values on hand. Let's move on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gradlsp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradlsp is a lsp that returns a graph of convential computation (just like fblsplsp) in the forward result, and returns a graph of gradients taken with respect to the final result in the backward result.\n",
    "\n",
    "How do we do this? The operator type for gradlsp includes a two functions: one for the output value of the operator at the  arguments and one for the gradient of the operator at these arguments. At each operator application, we store both the value and the gradient in the resulting value.\n",
    "\n",
    "Any operation that returns a value records, in that returned value, \n",
    "the necessary information to compute a gradient tree with respect either that value,\n",
    "or to some future value generated from it. \n",
    "In practice, this forms a graph, and gradient computation requires a topological sort.\n",
    "However, we require that the compute graph be a DAG, and simply treat it as a tree.\n",
    "This is very inefficient: if the DAG isn't treelike, we are performing wasted computations.\n",
    "\n",
    "When computing the backward result, we propogate the gradient of the final value $y$ backwards. This consists of vector multiplication between the original value and the intermediate gradients. At each intermediate value $v$, we obtain an `adjoint` value $\\frac{dy}{dv}$, the derivative of $v$ with respect to the final result $y$. \n",
    "\n",
    "The detach operation `($ value)` detaches the compute graph of `value` from it, resulting in a new compute graph consisting of `value` only.\n",
    "The (singular) node of the gradient DAG rooted at `value`, in any case, will be zero.\n",
    "This value, though it may depend on other values in actuality, is \"held constant\" from the standpoint of the gradient computation.\n",
    "\n",
    "Any operation on a value in gradlsp is pure with respect to the boxed value - it does not modify the original value. Furthermore, all operations are pure with respect to the value's gradient graph. Even the detach operation simply returns a new value with a degenerate graph. This ensures that the gradient graph is a DAG: a cycle in the graph would require a changed (impure) value.\n",
    "\n",
    "Note that if a node's value is \"held constant\" in some other way - such as through multiplication by zero - this will not detach the gradient tree and create a degenerate tree. However, the gradient of all child nodes with respect to this node may be zero.\n",
    "\n",
    "Gradlsp is definitely a toy language. \n",
    "For instance, implementing an $n$ layer fully connected neural network with $a$ units in the widest layer in gradlsp will require $O(a^n)$ time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FBHookLsp(Lsp):\n",
    "    \"\"\"An Lsp that computes the forward and backward results using a hook from stack evaluation.\"\"\"\n",
    "    def eval_str(self, code_str):\n",
    "        stack = self.parse(self.tokenize(code_str))\n",
    "        evaled = self.eval_stack(stack)\n",
    "        return (\n",
    "            evaled.forward(),\n",
    "            evaled.backward()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradLspValue(object):\n",
    "    def __init__(self, value, gradient = [], children = [], symbol = None):\n",
    "        self.gradient = gradient\n",
    "        self.children = children\n",
    "        self.value = value\n",
    "        self.symbol = symbol\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"<GLV {self.value}, gradient={self.gradient}, with {len(self.children)} children>\"\n",
    "        \n",
    "    def detach(self):\n",
    "        return GradLspValue(self.value, [], [], self.symbol)\n",
    "    \n",
    "    def forward(self):\n",
    "        return (self.value,) + ((\n",
    "            [child.forward() for child in self.children],\n",
    "        ) if len(self.children) > 0 else tuple())\n",
    "    \n",
    "    def backward(self, adjoint=1):\n",
    "        if len(self.children) == 0:\n",
    "            return adjoint\n",
    "        return (adjoint,) + ((\n",
    "            [child.backward(adjoint * derivative) \n",
    "             for child, derivative in zip(self.children, self.gradient)],\n",
    "        ) if len(self.children) > 0 else tuple())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradLspOperator(object):\n",
    "    def __init__(self, symbol):\n",
    "        self.symbol = symbol\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"<GLF {self.symbol}>\"\n",
    "        \n",
    "    def __call__(self, *args):\n",
    "        raise NotImplemented()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_token = re.compile(\"^\\d+$\")\n",
    "float_token = re.compile(\"^\\d+(\\.\\d*)$\")\n",
    "#string_token = re.compile(\"^\\\"([^\\\"]*)\\\"\")\n",
    "\n",
    "def gradlsp_atomizer(token):\n",
    "    if int_token.match(token):\n",
    "        return GradLspValue(int(token))\n",
    "    if float_token.match(token):\n",
    "        return  GradLspValue(float(token))\n",
    "    raise ValueError(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradLspOperatorOperator(GradLspOperator):\n",
    "    def __init__(self, symbol, function, grad_function):\n",
    "        super().__init__(symbol)\n",
    "        self.function = function\n",
    "        self.grad_function = grad_function\n",
    "        \n",
    "    def __call__(self, *args):\n",
    "        result = GradLspValue(\n",
    "            self.function(*map(lambda glv: glv.value, args)),\n",
    "            self.grad_function(*map(lambda glv: glv.value, args)),\n",
    "            args\n",
    "        )\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "plus = GradLspOperatorOperator(\n",
    "    '+',\n",
    "    lambda *args: sum(args),\n",
    "    lambda *args: [1,] * len(args)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "minus = GradLspOperatorOperator(\n",
    "    '-',\n",
    "    lambda *args: args[0] - sum(args[1:]),\n",
    "    lambda *args: [1,] + [-1,] * (len(args) - 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod = GradLspOperatorOperator(\n",
    "    '*',\n",
    "    lambda *args: reduce(operator.mul, args, 1),\n",
    "    lambda *args: [reduce(operator.mul, (args[:i] + args[i+1:]), 1) for i in range(len(args))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "quot = GradLspOperatorOperator(\n",
    "    '/',\n",
    "    lambda x, y: x / y,\n",
    "    lambda x, y: [1/y, -(x/(math.pow(y, 2)))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "sin = GradLspOperatorOperator(\n",
    "    'sin',\n",
    "    lambda x: math.sin(x),\n",
    "    lambda x: [math.cos(x)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos = GradLspOperatorOperator(\n",
    "    'cos',\n",
    "    lambda x: math.cos(x),\n",
    "    lambda x: [-math.sin(x)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetachOperator(GradLspOperator):\n",
    "    def __call__(self, *args):\n",
    "        if len(args) == 1:\n",
    "            return GradLspValue(args[0].value)\n",
    "        return [GradLspValue(arg.value) for arg in args]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "detach = DetachOperator('$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = GradLspValue(math.pi, symbol='pi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradlsp = FBHookLsp(\n",
    "    GradLspValue, \n",
    "    GradLspOperator, \n",
    "    gradlsp_atomizer, \n",
    "    { f.symbol: f for f in [plus, minus, prod, quot, sin, cos, pi, detach] }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((-6.0, [(6, [(3,), (2,)]), (-1.0, [(3.141592653589793,)])]),\n",
       " (1, [(-1.0, [-2.0, -3.0]), (6, [-7.347880794884119e-16])]))"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradlsp.eval_str(\"(* (* 3 2) (cos pi))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## jacoblsp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradlsp isn't very useful. \n",
    "It works on scalar valued functions only. \n",
    "It's hard to implement more than a best fit line with it.\n",
    "\n",
    "Jacoblsp is our next step.\n",
    "An operator in jacoblsp maps $\\mathbb R^n \\to \\mathbb R^m$.\n",
    "Correspondingly, instead of the gradient, jacoblsp computes the Jacobian matrix for each operation.\n",
    "In the backwards result, we obtain an adjoint tree of the forwards computation.\n",
    "\n",
    "Each value in jacoblsp is a 1-dimensional array.\n",
    "An array is expressed as a literal `1,2,3`. Trailing commas are allowed, but spaces are not.\n",
    "For instance, `(dot 1,2,3 4,5,6)`  will compute the dot product of $[1,2,3]$ with $[4,5,6]$\n",
    "Note that every value in jacoblsp is an array: scalar values are simply arrays of size one.\n",
    "\n",
    "Jacoblsp can express arbitrary functions over $R^n$ now, but in practice, doing so can be quite unwieldy. In particular, because we work with 1-dimensional arrays everywhere, we have to somehow keep track of size transformations if we want to compute operations like matrix multiplication. Our next language will address this problem, and is actually very simple to implement on top of Jacoblsp.\n",
    "\n",
    "Note that Jacoblsp is still very inefficient. We compute every subtree of the compute DAG for every backwards operation. If our DAG isn't treelike, we are performing wasted computations. It's easier to express combinatorically complex programs in jacoblsp than it was in gradlsp, so this problem is more worrying. We'll come back to it soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JacobLspValue(object):\n",
    "    def __init__(self, value, jacobians = None, children=[], symbol = None):\n",
    "        self.jacobians = jacobians\n",
    "        self.children = children\n",
    "        self.value = value\n",
    "        self.symbol = symbol\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"<JLV {self.value}, jacobians={self.jacobians}, with {len(self.children)} children>\"\n",
    "    \n",
    "    def forward(self):\n",
    "        if not self.children:\n",
    "            return (self.value,)\n",
    "        return (self.value, [child.forward() for child in self.children])\n",
    "    \n",
    "    def backward(self, adjoint=None):\n",
    "        if not self.children:\n",
    "            return (adjoint,)\n",
    "        if adjoint is None:\n",
    "            adjoint = np.ones(self.jacobians[0].shape[0])\n",
    "            \n",
    "        # adjoint = (1 x m) where m is the size of this vector\n",
    "        # self.jacobians = (m x len_i) x len(children) where total size is m x n\n",
    "        return (adjoint, [np.dot(adjoint, child_jacobian) for child_jacobian, child in zip(self.jacobians, self.children)])\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JacobLspOperator(object):\n",
    "    def __init__(self, symbol, function, jacob_function, max_args=None):\n",
    "        self.function = function\n",
    "        self.jacob_function = jacob_function\n",
    "        self.symbol = symbol\n",
    "        self.max_args = max_args\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"<JLF {self.symbol}>\"\n",
    "        \n",
    "    def __call__(self, *args):\n",
    "        if self.max_args is not None and len(args) > self.max_args:\n",
    "            raise ArgumentException()\n",
    "            \n",
    "        result = JacobLspValue(\n",
    "            self.function(*map(lambda jlv: jlv.value, args)),\n",
    "            self.jacob_function(*map(lambda jlv: jlv.value, args)),\n",
    "            args\n",
    "        )\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_arr_token= re.compile(\"^(\\d+,)*\\d,?$\")\n",
    "float_arr_token= re.compile(\"^(\\d+(\\.\\d*)?,)*\\d+(\\.\\d*)?,?$\")\n",
    "\n",
    "def jacoblsp_atomizer(token):\n",
    "    if int_arr_token.match(token):\n",
    "        return JacobLspValue(np.array(list(map(int, filter(bool, token.split(',')))), dtype='int'))\n",
    "    if int_arr_token.match(token):\n",
    "        return JacobLspValue(np.array(list(map(float, filter(bool, token.split(',')))), dtype='float'))\n",
    "    raise ValueError(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "jplus = JacobLspOperator(\n",
    "    '+',\n",
    "    lambda *args: np.stack(args).sum(axis=0),\n",
    "    lambda *args: [np.ones_like(a) for a in args]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "jminus = JacobLspOperator(\n",
    "    '-',\n",
    "    lambda *args: args[0] - np.stack(args[1:]).sum(axis=0),\n",
    "    lambda *args: [np.ones_like(args[0])] + [np.full_like(a, -1) for a in args[1:]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "jprod = JacobLspOperator(\n",
    "    '*',\n",
    "    lambda *args: np.stack(args).prod(axis=0),\n",
    "    lambda *args: [np.stack(args[:i] + args[i+1:]) for i in range(len(args))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "jdot = JacobLspOperator(\n",
    "    '*.',\n",
    "    lambda x, y: np.dot(x, y),\n",
    "    lambda x, y: [y.T, x.T],\n",
    "    max_args = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "jquot = JacobLspOperator(\n",
    "    '/',\n",
    "    lambda x, y: x / y,\n",
    "    lambda *args: [1/y, -(x/(math.pow(y, 2)))],\n",
    "    max_args = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "jcos = JacobLspOperator(\n",
    "    'cos',\n",
    "    lambda x: np.cos(x),\n",
    "    lambda x: [-np.sin(x)],\n",
    "    max_args = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsin = JacobLspOperator(\n",
    "    'sin',\n",
    "    lambda x: np.sin(x),\n",
    "    lambda x: [np.cos(x)],\n",
    "    max_args = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "jacoblsp = FBHookLsp(\n",
    "    JacobLspValue,\n",
    "    JacobLspOperator,\n",
    "    jacoblsp_atomizer,\n",
    "    { f.symbol: f for f in [jplus, jminus, jprod, jquot, jsin, jcos, jdot] }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((31, [(array([1, 2, 3]),), (array([3, 5, 6]),)]),\n",
       " (array([ 1.,  1.,  1.]), [14.0, 6.0]))"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacoblsp.eval_str('(*. 1,2,3 3,5,6)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
